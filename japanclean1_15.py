# -*- coding: utf-8 -*-
"""JapanClean1-15

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18I4Zck_Fn5eJ4Z-9_uur-CoEXA9Fu44x
"""

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_10.csv"

# Read the CSV file
df = pd.read_csv("//chunk_10.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_14.csv"

# Read the CSV file
df = pd.read_csv("//chunk_14.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_15.csv"

# Read the CSV file
df = pd.read_csv("//chunk_15.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_3.csv"

# Read the CSV file
df = pd.read_csv("//chunk_3.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_11.csv"

# Read the CSV file
df = pd.read_csv("//chunk_11.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_13.csv"

# Read the CSV file
df = pd.read_csv("//chunk_13.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_12.csv"

# Read the CSV file
df = pd.read_csv("//chunk_12.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_4.csv"

# Read the CSV file
df = pd.read_csv("//chunk_4.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_5.csv"

# Read the CSV file
df = pd.read_csv("//chunk_5.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_6.csv"

# Read the CSV file
df = pd.read_csv("//chunk_6.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_7.csv"

# Read the CSV file
df = pd.read_csv("//chunk_7.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_8.csv"

# Read the CSV file
df = pd.read_csv("//chunk_8.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_9.csv"

# Read the CSV file
df = pd.read_csv("//chunk_9.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import pandas as pd
import re

# Define the path to the CSV file
file_path = "//chunk_16.csv"

# Read the CSV file
df = pd.read_csv("//chunk_16.csv")

# Function to check if an email address is valid
def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}' # Corrected the regex
    return re.match(email_regex, email) is not None

# Drop rows with any null values in the 'email' column if it exists
# Check if 'email' column exists before dropping nulls
if 'email' in df.columns:
    df_cleaned = df.dropna(subset=['email'])
else:
    df_cleaned = df.copy()  # If 'email' column doesn't exist, skip dropping nulls
    print("Warning: 'email' column not found in the DataFrame.")

# Identify and remove rows with invalid email addresses only if 'email' column exists
if 'email' in df_cleaned.columns:
    invalid_emails = df_cleaned[~df_cleaned['email'].apply(is_valid_email)]
    df_cleaned = df_cleaned[df_cleaned['email'].apply(is_valid_email)]
else:
    invalid_emails = pd.DataFrame()  # Create an empty DataFrame if 'email' column doesn't exist
    print("Warning: 'email' column not found, skipping email validation.")

# Save invalid rows to a dump file
dump_file_path = "invalid_rows_dump.csv"
invalid_emails.to_csv(dump_file_path, index=False)

# Print the cleaned DataFrame and the invalid rows
print("Cleaned DataFrame:")
print(df_cleaned)
print("\nInvalid Email Rows:")
print(invalid_emails)

import os
import glob

directory = "//mergedJapanLB"
# Specify the directory containing the chunk files

# Get a list of all chunk files in the directory
chunk_files = glob.glob(os.path.join(directory, "*.//chunk_10.csv"))

# Create an empty list to store the merged data
merged_data = []

# Iterate through each chunk file and append its data to the merged list
for chunk_file in chunk_files:
  with open(chunk_file, 'r') as f:
    data = f.read()
    merged_data.append(data)

# Join all the data chunks into a single string
merged_data = ''.join(merged_data)

# Save the merged data to a new file
with open("merged_data.txt", 'w') as f:
  f.write(merged_data)

# prompt: using the file path"/content/ChunksMerged" merge all of the csv chunks into one file called valid data

import pandas as pd
import os
import glob

def merge_csv_chunks(directory, output_file):
  """Merges all CSV chunks in a directory into a single file.

  Args:
    directory: The directory containing the CSV chunks.
    output_file: The path to the output file where the merged data will be saved.
  """

  # Get a list of all CSV files in the directory
  chunk_files = glob.glob(os.path.join(directory, "*.csv"))

  # Create an empty list to store the DataFrames
  dfs = []

  # Iterate through each chunk file and read it into a DataFrame
  for chunk_file in chunk_files:
    try:
      df = pd.read_csv(chunk_file)
      dfs.append(df)
    except Exception as e:
      print(f"Error reading file {chunk_file}: {e}")

  # Concatenate all DataFrames into a single DataFrame
  merged_df = pd.concat(dfs, ignore_index=True)

  # Save the merged DataFrame to the output file
  merged_df.to_csv(output_file, index=False)
  print(f"Merged data saved to {output_file}")

# Example usage:
directory = "/content/ChunksMerged" # Replace with your directory path
output_file = "valid_data.csv"  # Replace with your desired output file name

merge_csv_chunks(directory, output_file)

# prompt: using the file "/content/valid_data.csv" remove duplicates found in the columns "mail_address & login_id"

import pandas as pd

# Load the CSV file
df = pd.read_csv("/content/valid_data.csv")

# Remove duplicates based on 'mail_address' and 'login_id'
df_no_duplicates = df.drop_duplicates(subset=['mail_address', 'login_id'])

# Save the DataFrame without duplicates to a new CSV file
df_no_duplicates.to_csv("deduplicated_valid_data.csv", index=False)

print("Deduplicated data saved to 'deduplicated_valid_data.csv'")

# prompt: using "/content/deduplicated_valid_data.csv" remove email adress with invalid formats found in "mail_address", extract and add invalid emails to "/content/invalid_rows_dump.csv"

import pandas as pd
import re

def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return re.match(email_regex, email) is not None

# Load the CSV file
df = pd.read_csv("/content/deduplicated_valid_data.csv")

# Identify rows with invalid email addresses
invalid_emails_df = df[~df['mail_address'].apply(is_valid_email)]

# Remove rows with invalid email addresses from the main DataFrame
df_cleaned = df[df['mail_address'].apply(is_valid_email)]

# Save the cleaned DataFrame to a new CSV file
df_cleaned.to_csv("/content/final_cleaned_data.csv", index=False)

# Append invalid email rows to the existing invalid_rows_dump.csv
try:
  existing_invalid_emails = pd.read_csv("/content/invalid_rows_dump.csv")
  updated_invalid_emails = pd.concat([existing_invalid_emails, invalid_emails_df], ignore_index=True)
except FileNotFoundError:
  updated_invalid_emails = invalid_emails_df

updated_invalid_emails.to_csv("/content/invalid_rows_dump.csv", index=False)

print("Cleaned data saved to '/content/final_cleaned_data.csv'")
print("Invalid email rows appended to '/content/invalid_rows_dump.csv'")

import pandas as pd
import re

def is_valid_email(email):
    email_regex = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    return re.match(email_regex, email) is not None

# Load the CSV file
df = pd.read_csv("/content/deduplicated_valid_data.csv")

# Identify rows with invalid email addresses
invalid_emails_df = df[~df['mail_address'].apply(is_valid_email)]

# Remove rows with invalid email addresses from the main DataFrame
df_cleaned = df[df['mail_address'].apply(is_valid_email)]

# Save the cleaned DataFrame to a new CSV file
df_cleaned.to_csv("/content/final_cleaned_data.csv", index=False)

# Append invalid email rows to the existing invalid_rows_dump.csv
try:
  # Try reading the existing file, if it exists and has data
  existing_invalid_emails = pd.read_csv("/content/invalid_rows_dump.csv")
  updated_invalid_emails = pd.concat([existing_invalid_emails, invalid_emails_df], ignore_index=True)
except (FileNotFoundError, pd.errors.EmptyDataError):
  # If the file doesn't exist or is empty, use the new invalid emails
  updated_invalid_emails = invalid_emails_df

# Save the updated invalid emails
updated_invalid_emails.to_csv("/content/invalid_rows_dump.csv", index=False)

print("Cleaned data saved to '/content/final_cleaned_data.csv'")
print("Invalid email rows appended to '/content/invalid_rows_dump.csv'")